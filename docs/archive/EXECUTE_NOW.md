# ğŸš€ ç«‹å³æ‰§è¡Œ - åˆè§„å®‰å…¨RLæ–¹æ¡ˆ

**çŠ¶æ€**: âœ… æ–¹æ¡ˆå·²ä¼˜åŒ–ï¼Œå¯ç«‹å³æ‰§è¡Œ  
**ç›®æ ‡**: é€šè¿‡RLæ”¹å–„æ¨¡å‹åˆè§„å®‰å…¨æ€§  
**æ—¶é—´**: 2024-11-20

---

## ğŸ“‹ å¿«é€Ÿæ£€æŸ¥æ¸…å•

### âœ… å·²å®Œæˆçš„å‡†å¤‡å·¥ä½œ

- [x] å®‰å…¨çº¢é˜Ÿæ•°æ®é›† (`data/rl/safety_red_team.jsonl`) - 10ä¸ªæ ·æœ¬
- [x] RLæ•°æ®é‡‡æ ·è„šæœ¬ä¼˜åŒ– (`scripts/prepare_rl_data.py`)
- [x] å¥–åŠ±å‡½æ•°å®‰å…¨è§„åˆ™å¢å¼º (`scripts/reward_fn.py`)
- [x] æ•°æ®é›†é€‰æ‹©æ–¹æ¡ˆ (`docs/dataset_selection_guide.md`)
- [x] å¤šæºæ•°æ®åŠ è½½è„šæœ¬ (`scripts/prepare_data_multi_source.py`)

### ğŸ“Š æ–¹æ¡ˆç‰¹ç‚¹

| ç»´åº¦ | é…ç½® |
|------|------|
| **æ•°æ®æº** | medical-o1 (æ¨ç†é“¾+éªŒè¯) |
| **å®‰å…¨æ ·æœ¬** | 10ä¸ªçº¢é˜Ÿ Ã— 3å€è¿‡é‡‡æ · |
| **é‡‡æ ·æ¯”ä¾‹** | 60%é«˜é£é™© + 40%ä¸€èˆ¬ |
| **å®‰å…¨è§„åˆ™** | 5å¤§ç±»ï¼ˆå¤„æ–¹è¯/æ€¥ç—‡/å­•å„¿/è¯Šæ–­/å¿ƒç†ï¼‰ |
| **æƒ©ç½šåŠ›åº¦** | -3.0 to +2.0 (å¼ºåŒ–å®‰å…¨) |
| **æƒé‡é…ç½®** | 0.5è§„åˆ™ + 0.5æ•™å¸ˆ |

---

## ğŸ¯ 3æ­¥æ‰§è¡Œæ–¹æ¡ˆ

### Step 1: å‡†å¤‡æ•°æ®ï¼ˆ5åˆ†é’Ÿï¼‰

```bash
# æ¿€æ´»ç¯å¢ƒ
cd /Users/zhangchenxi/Documents/project/qwen3-medical-finetune
source .venv/bin/activate

# æ–¹å¼A: ä½¿ç”¨medical-o1æ•°æ®é›†ï¼ˆæ¨èï¼‰
python3 scripts/prepare_data_multi_source.py medical-o1

# æ–¹å¼B: å¦‚æœæ²¡æœ‰ç½‘ç»œï¼Œä½¿ç”¨ç°æœ‰æ•°æ®
python3 scripts/prepare_data.py  # ä½¿ç”¨æœ¬åœ°ç¼“å­˜
```

**é¢„æœŸè¾“å‡º**:
```
âœ… Data prepared: {'train': XXXX, 'dev': XXX, 'test': XXX}
```

---

### Step 2: å‡†å¤‡RLè®­ç»ƒæ•°æ®ï¼ˆ1åˆ†é’Ÿï¼‰

```bash
python3 scripts/prepare_rl_data.py
```

**é¢„æœŸè¾“å‡º**:
```
ğŸ”„ Loading source datasets...
   Gold: 1, Red: 2, Safety-Red: 10, Train: XXXX
ğŸ“Š Sampling from train: XXX high-risk + XXX general

âœ… Generated XXXX RL prompts at data/rl/training_prompts.jsonl
   ğŸ“Š Risk Level Distribution:
      critical: XX (XX%)
      high: XX (XX%)
      medium: XX (XX%)
      low: XX (XX%)
   ğŸ¯ Strategy: Safety-focused (60% high-risk + oversampled safety cases)
```

**å…³é”®æŒ‡æ ‡**:
- `critical` + `high` åº”è¯¥ >40%
- Safety-Redæ ·æœ¬åº”è¢«è¿‡é‡‡æ ·ï¼ˆå‡ºç°3æ¬¡ï¼‰

---

### Step 3: éªŒè¯æ•°æ®è´¨é‡ï¼ˆå¯é€‰ä½†æ¨èï¼‰

```bash
# æŸ¥çœ‹æ€»æ•°
cat data/rl/training_prompts.jsonl | wc -l

# æŸ¥çœ‹é«˜é£é™©æ ·æœ¬æ•°é‡
grep '"risk_level": "critical"' data/rl/training_prompts.jsonl | wc -l
grep '"risk_level": "high"' data/rl/training_prompts.jsonl | wc -l

# æŸ¥çœ‹å®‰å…¨å…³æ³¨æ ·æœ¬
grep '"safety_concern"' data/rl/training_prompts.jsonl | wc -l

# é¢„è§ˆç¬¬ä¸€ä¸ªæ ·æœ¬
head -n 1 data/rl/training_prompts.jsonl | jq
```

---

## ğŸ”§ åç»­æ­¥éª¤ï¼ˆéœ€è¦SFTæ¨¡å‹ï¼‰

### Step 4: è¿è¡ŒSFTè®­ç»ƒï¼ˆå¦‚æœªå®Œæˆï¼‰

```bash
# ä»…åœ¨æ²¡æœ‰SFTæ¨¡å‹æ—¶è¿è¡Œ
python3 scripts/train_lora.py
```

**æ£€æŸ¥SFTæ¨¡å‹**:
```bash
ls -lh models/lora/final_lora/
# åº”è¯¥çœ‹åˆ°: adapter_config.json, adapter_model.bin
```

---

### Step 5: å¯åŠ¨RLè®­ç»ƒ

```bash
# ï¼ˆå¯é€‰ï¼‰é…ç½®DeepSeek API
export DEEPSEEK_API_KEY="your_key_here"
# æ— APIå¯†é’¥ä¼šè‡ªåŠ¨ä½¿ç”¨Mockæ¨¡å¼

# å¯åŠ¨PPOè®­ç»ƒ
python3 scripts/train_ppo.py
```

**è®­ç»ƒå‚æ•°**:
- Batch size: 4
- Learning rate: 1.41e-5
- Target KL: 0.1
- å®‰å…¨æƒé‡: 0.5

**é¢„æœŸæ—¶é—´**:
- 2000æ ·æœ¬ Ã— 4 epochs â‰ˆ 2-4å°æ—¶ï¼ˆå•å¡24GB GPUï¼‰

---

## ğŸ“Š ç›‘æ§è®­ç»ƒ

### å…³é”®æŒ‡æ ‡

```python
# è®­ç»ƒè¿‡ç¨‹ä¸­è§‚å¯Ÿ
- Rewardè¶‹åŠ¿: åº”ä»è´Ÿå€¼é€æ¸ä¸Šå‡åˆ°æ­£å€¼
- KLæ•£åº¦: ä¿æŒåœ¨ 0.05-0.15
- å®‰å…¨è¿è§„æƒ©ç½š: åº”é€æ¸å‡å°‘
```

### æ—¥å¿—ä½ç½®
```bash
# è®­ç»ƒæ—¥å¿—
models/rl/checkpoints/training.log

# DeepSeekæ•™å¸ˆè¯„åˆ†ç¼“å­˜
data/rl/teacher_judgements.jsonl

# å¥–åŠ±æ›²çº¿
models/rl/checkpoints/rewards.csv
```

---

## âœ… éªŒè¯æ•ˆæœ

### åœ¨red_teamä¸Šæµ‹è¯•

```bash
# ä½¿ç”¨RLæ¨¡å‹
python3 scripts/eval_auto.py \
  --model_path models/rl/final_model \
  --test_file data/processed/red_team.jsonl

# å¯¹æ¯”SFTæ¨¡å‹
python3 scripts/eval_auto.py \
  --model_path models/lora/final_lora \
  --test_file data/processed/red_team.jsonl
```

### é‡ç‚¹è¯„ä¼°æŒ‡æ ‡

| æŒ‡æ ‡ | è®¡ç®—æ–¹å¼ | ç›®æ ‡ |
|------|----------|------|
| **å®‰å…¨è¿è§„ç‡** | åŒ…å«å¤„æ–¹è¯æ»¥ç”¨å»ºè®®çš„æ¯”ä¾‹ | <5% |
| **ç´§æ€¥å°±åŒ»å»ºè®®è¦†ç›–** | æ€¥ç—‡æ ·æœ¬ä¸­å»ºè®®ç«‹å³å°±åŒ»çš„æ¯”ä¾‹ | >90% |
| **é™å®šæ€§è¡¨è¿°** | åŒ…å«"å¯èƒ½"ã€"å»ºè®®"ç­‰çš„æ¯”ä¾‹ | >75% |
| **æ¨ç†é“¾ä¿ç•™ç‡** | åŒ…å«<think>æ ‡ç­¾çš„æ¯”ä¾‹ | >90% |

---

## ğŸ¯ ç«‹å³æ‰§è¡Œå‘½ä»¤ï¼ˆå¤åˆ¶ç²˜è´´ï¼‰

```bash
#!/bin/bash
# åˆè§„å®‰å…¨RLæ–¹æ¡ˆ - ä¸€é”®æ‰§è¡Œ

set -e  # é‡é”™é€€å‡º

echo "ğŸš€ å¼€å§‹æ‰§è¡Œåˆè§„å®‰å…¨RLæ–¹æ¡ˆ..."
echo ""

# Step 1: å‡†å¤‡æ•°æ®
echo "Step 1/2: å‡†å¤‡è®­ç»ƒæ•°æ®..."
cd /Users/zhangchenxi/Documents/project/qwen3-medical-finetune
source .venv/bin/activate
python3 scripts/prepare_data_multi_source.py medical-o1

# Step 2: å‡†å¤‡RLæ•°æ®
echo ""
echo "Step 2/2: å‡†å¤‡RLè®­ç»ƒæç¤º..."
python3 scripts/prepare_rl_data.py

# éªŒè¯
echo ""
echo "âœ… æ•°æ®å‡†å¤‡å®Œæˆï¼"
echo ""
echo "ğŸ“Š æ•°æ®ç»Ÿè®¡:"
echo "  æ€»æ ·æœ¬æ•°: $(cat data/rl/training_prompts.jsonl | wc -l)"
echo "  Critical: $(grep '"risk_level": "critical"' data/rl/training_prompts.jsonl | wc -l)"
echo "  High: $(grep '"risk_level": "high"' data/rl/training_prompts.jsonl | wc -l)"
echo "  å®‰å…¨å…³æ³¨: $(grep '"safety_concern"' data/rl/training_prompts.jsonl | wc -l)"
echo ""
echo "ğŸ¯ ä¸‹ä¸€æ­¥ï¼š"
echo "  1. æ£€æŸ¥æ˜¯å¦æœ‰SFTæ¨¡å‹: ls models/lora/final_lora/"
echo "  2. å¦‚æœ‰ï¼Œè¿è¡Œ: python3 scripts/train_ppo.py"
echo "  3. å¦‚æ— ï¼Œå…ˆè¿è¡Œ: python3 scripts/train_lora.py"
echo ""
```

---

## ğŸ“š ç›¸å…³æ–‡æ¡£

| æ–‡æ¡£ | ç”¨é€” |
|------|------|
| [SAFETY_RL_PLAN.md](SAFETY_RL_PLAN.md) | å®Œæ•´æ–¹æ¡ˆè¯„ä¼°ä¸ä¼˜åŒ–è¯´æ˜ |
| [DATASET_SOLUTION.md](DATASET_SOLUTION.md) | æ•°æ®é›†é€‰æ‹©æ–¹æ¡ˆ |
| [docs/rl_quickstart.md](docs/rl_quickstart.md) | RLè®­ç»ƒå¿«é€Ÿå…¥é—¨ |
| [data/rl/reward_rules.md](data/rl/reward_rules.md) | å¥–åŠ±è§„åˆ™è¯¦ç»†è¯´æ˜ |

---

## ğŸ†˜ troubleshooting

### é—®é¢˜1: medical-o1ä¸‹è½½å¤±è´¥

**è§£å†³æ–¹æ¡ˆ**:
```bash
# æ–¹æ¡ˆA: ä½¿ç”¨æœ¬åœ°ç¼“å­˜æ•°æ®
python3 scripts/prepare_data.py

# æ–¹æ¡ˆB: æ‰‹åŠ¨ä¸‹è½½
open https://modelscope.cn/datasets/FreedomIntelligence/medical-o1-reasoning-SFT
# ä¸‹è½½åæ”¾åˆ° data/raw/medical_o1_sft.json
python3 scripts/prepare_data_multi_source.py medical-o1
```

### é—®é¢˜2: æ ·æœ¬æ•°é‡å¤ªå°‘

**æ£€æŸ¥**:
```bash
cat data/raw/delicate_medical_r1_data.jsonl | wc -l
```

**å¦‚æœ<100**, æ•°æ®æ˜¯mockæ•°æ®ï¼Œéœ€è¦ï¼š
1. ä¸‹è½½çœŸå®æ•°æ®é›†ï¼Œæˆ–
2. è°ƒæ•´TARGET_SIZE: `vim scripts/prepare_rl_data.py` (æ”¹ä¸º100)

### é—®é¢˜3: æ²¡æœ‰SFTæ¨¡å‹

**è¿è¡ŒSFTè®­ç»ƒ**:
```bash
python3 scripts/train_lora.py
```

**æˆ–ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹ç›´æ¥å¼€å§‹RL**ï¼ˆä¸æ¨èï¼Œæ•ˆæœå·®ï¼‰

---

## âœ… æœ€ç»ˆç¡®è®¤

### åœ¨æ‰§è¡Œå‰ç¡®è®¤

- [ ] å·²é˜…è¯» `SAFETY_RL_PLAN.md`
- [ ] ç†è§£æ–¹æ¡ˆçš„å®‰å…¨ä¼˜åŒ–ç­–ç•¥
- [ ] è™šæ‹Ÿç¯å¢ƒå·²æ¿€æ´»
- [ ] æœ‰è¶³å¤Ÿç£ç›˜ç©ºé—´ï¼ˆéœ€è¦10GB+ï¼‰
- [ ] ï¼ˆå¯é€‰ï¼‰å·²é…ç½®DeepSeek APIå¯†é’¥

### æ‰§è¡Œåç¡®è®¤

- [ ] RLè®­ç»ƒæ•°æ® >100 samples
- [ ] é«˜é£é™©æ ·æœ¬ >40%
- [ ] å®‰å…¨å…³æ³¨æ ·æœ¬å·²åŒ…å«
- [ ] æ— æŠ¥é”™ä¿¡æ¯

---

**å‡†å¤‡å¥½äº†å—ï¼Ÿå¼€å§‹æ‰§è¡Œå§ï¼** ğŸš€

**æ¨è**: å…ˆè¿è¡ŒStep 1-3éªŒè¯æ•°æ®ï¼Œç¡®è®¤æ— è¯¯åå†è¿›è¡ŒRLè®­ç»ƒã€‚
