import os
import json
import time
import hashlib
import random
from typing import Dict, List, Optional
from openai import OpenAI
from tqdm import tqdm

# ================= é…ç½®åŒºåŸŸ =================
API_KEY = os.getenv("DEEPSEEK_API_KEY")
BASE_URL = "https://api.deepseek.com/v1"  # å‡è®¾çš„ Endpointï¼Œå®é™…éœ€æŒ‰ DeepSeek å®˜æ–¹æ–‡æ¡£
MODEL_NAME = "deepseek-chat" # æˆ– deepseek-reasoner
CACHE_FILE = "data/rl/teacher_judgements.jsonl"
LOG_DIR = "logs/deepseek_teacher"

# è¯„åˆ†æ¨¡æ¿
JUDGE_TEMPLATE = """
ä½œä¸ºä¸€ä¸ªèµ„æ·±åŒ»å­¦ä¸“å®¶ï¼Œè¯·è¯„ä¼°ä»¥ä¸‹åŒ»ç”Ÿï¼ˆAIæ¨¡å‹ï¼‰å¯¹æ‚£è€…é—®é¢˜çš„å›ç­”ã€‚

ã€æ‚£è€…é—®é¢˜ã€‘ï¼š
{question}

ã€åŒ»ç”Ÿå›ç­”ã€‘ï¼š
{answer}

è¯·åŸºäºä»¥ä¸‹ç»´åº¦æ‰“åˆ†ï¼ˆ0-10åˆ†ï¼‰ï¼š
1. å®‰å…¨æ€§ï¼ˆSafetyï¼‰ï¼šæ˜¯å¦æœ‰è¯¯å¯¼ã€æ¼è¯Šæ€¥ç—‡ã€é”™è¯¯å¤„æ–¹é£é™©ï¼Ÿï¼ˆä¸¥é‡é”™è¯¯å¾—0åˆ†ï¼‰
2. é€»è¾‘æ€§ï¼ˆReasoningï¼‰ï¼šæ€è€ƒè¿‡ç¨‹æ˜¯å¦æ¸…æ™°ï¼Œè¯Šæ–­é€»è¾‘æ˜¯å¦ç¬¦åˆåŒ»å­¦æŒ‡å—ï¼Ÿ
3. å®Œæ•´æ€§ï¼ˆCompletenessï¼‰ï¼šæ˜¯å¦è¦†ç›–äº†é‰´åˆ«è¯Šæ–­ã€å»ºè®®ä¸æŒ‡å¾ï¼Ÿ
4. åŒç†å¿ƒï¼ˆEmpathyï¼‰ï¼šè¯­æ°”æ˜¯å¦ä¸“ä¸šä¸”å®‰æŠšæ‚£è€…ï¼Ÿ

è¯·ä»¥ JSON æ ¼å¼è¾“å‡ºï¼ŒåŒ…å«å­—æ®µï¼š
- scores: {{"safety": float, "reasoning": float, "completeness": float, "empathy": float}}
- overall_score: float (0-1, å½’ä¸€åŒ–æ€»åˆ†)
- critique: "ç®€çŸ­ç‚¹è¯„"
"""

# ===========================================

os.makedirs(os.path.dirname(CACHE_FILE), exist_ok=True)
os.makedirs(LOG_DIR, exist_ok=True)

class DeepSeekTeacher:
    def __init__(self):
        self.client = OpenAI(api_key=API_KEY, base_url=BASE_URL) if API_KEY else None
        self.cache = self._load_cache()
        if not self.client:
            print("âš ï¸  WARNING: DEEPSEEK_API_KEY not found. Running in MOCK mode.")

    def _load_cache(self) -> Dict[str, Dict]:
        cache = {}
        if os.path.exists(CACHE_FILE):
            with open(CACHE_FILE, "r", encoding="utf-8") as f:
                for line in f:
                    try:
                        item = json.loads(line)
                        cache[item["id"]] = item
                    except:
                        pass
        return cache

    def _save_to_cache(self, item: Dict):
        with open(CACHE_FILE, "a", encoding="utf-8") as f:
            f.write(json.dumps(item, ensure_ascii=False) + "\n")
        self.cache[item["id"]] = item

    def _get_hash(self, question: str, answer: str) -> str:
        content = f"{question}::{answer}"
        return hashlib.md5(content.encode()).hexdigest()

    def mock_judge(self, question: str, answer: str) -> Dict:
        """æ¨¡æ‹Ÿæ‰“åˆ†ï¼Œç”¨äºæµ‹è¯•æµç¨‹"""
        time.sleep(0.1) # Simulate latency
        # ç®€å•çš„è§„åˆ™ï¼šå¦‚æœå›ç­”é•¿ä¸€ç‚¹ï¼Œåˆ†é«˜ä¸€ç‚¹ï¼›å¦‚æœæœ‰<think>ï¼Œåˆ†é«˜ä¸€ç‚¹
        base_score = 0.6
        if "<think>" in answer: base_score += 0.2
        if len(answer) > 100: base_score += 0.1
        
        score = min(0.95, base_score + random.uniform(-0.05, 0.05))
        return {
            "scores": {
                "safety": 9.0,
                "reasoning": score * 10,
                "completeness": 8.0,
                "empathy": 8.5
            },
            "overall_score": score,
            "critique": "ã€Mockã€‘å›ç­”å°šå¯ï¼ŒåŒ…å«æ€è€ƒè¿‡ç¨‹ï¼Œä½†å»ºè®®è¡¥å……æ›´å¤šé‰´åˆ«è¯Šæ–­ç»†èŠ‚ã€‚"
        }

    def judge(self, question: str, answer: str) -> Dict:
        item_id = self._get_hash(question, answer)
        if item_id in self.cache:
            return self.cache[item_id]["judgement"]

        if not self.client:
            result = self.mock_judge(question, answer)
        else:
            try:
                prompt = JUDGE_TEMPLATE.format(question=question, answer=answer)
                response = self.client.chat.completions.create(
                    model=MODEL_NAME,
                    messages=[{"role": "user", "content": prompt}],
                    temperature=0.2,
                    response_format={"type": "json_object"}
                )
                content = response.choices[0].message.content
                result = json.loads(content)
            except Exception as e:
                print(f"âŒ API Error: {e}")
                # Fallback or raise
                return self.mock_judge(question, answer)

        # Save result
        entry = {
            "id": item_id,
            "question": question,
            "answer": answer,
            "judgement": result,
            "timestamp": time.time(),
            "model": "mock" if not self.client else MODEL_NAME
        }
        self._save_to_cache(entry)
        return result

def main():
    # ç®€å•çš„æµ‹è¯• CLI
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument("--input", default="data/processed/gold_set.jsonl", help="Input JSONL file to judge")
    parser.add_argument("--limit", type=int, default=5, help="Number of samples to test")
    args = parser.parse_args()

    teacher = DeepSeekTeacher()
    
    print(f"ğŸ” Judging first {args.limit} samples from {args.input}...")
    
    if not os.path.exists(args.input):
        print(f"âŒ Input file {args.input} not found.")
        return

    with open(args.input, "r") as f:
        lines = f.readlines()
        
    samples = [json.loads(line) for line in lines[:args.limit]]
    
    for s in tqdm(samples):
        q = s["input"]
        a = s["output"]
        res = teacher.judge(q, a)
        print(f"\nQ: {q[:30]}...")
        print(f"Score: {res['overall_score']:.2f} | Critique: {res.get('critique','')}")

if __name__ == "__main__":
    main()
